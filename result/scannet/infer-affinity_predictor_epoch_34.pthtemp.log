/opt/conda/envs/xmask3d/lib/python3.9/site-packages/MinkowskiEngine/__init__.py:36: UserWarning: The environment variable `OMP_NUM_THREADS` not set. MinkowskiEngine will automatically set `OMP_NUM_THREADS=16`. If you want to set `OMP_NUM_THREADS` manually, please export it on the command line before running a python script. e.g. `export OMP_NUM_THREADS=12; python your_program.py`. It is recommended to set it below 24.
  warnings.warn(
/opt/conda/envs/xmask3d/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/root/code/XMask3D/third_party/X-Decoder/xdecoder/modeling/vision/encoder/transformer_encoder_deform.py:317: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  @autocast(enabled=False)
/opt/conda/envs/xmask3d/lib/python3.9/site-packages/kornia/feature/lightglue.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)
scene:
  scene_path: data/ScanNet
  dataset_name: scannet20
  test_cameras: false
  colmap_images: images
  colmap_eval_hold: 8
  downscale_ratio: 1
  white_background: false
  device: cuda:0
pipeline:
  convert_shs_python: false
  compute_cov3d_python: false
  debug: false
  seed: 0
model:
  sh_degree: 3
  model_dir: gaussians_model
  dynamic: false
  load_iteration: -1
  device: cuda:0
  num_workers: 0
fusion:
  img_dim:
  - 648
  - 484
  num_workers: 8
  model_2d: lseg
  depth: render
  depth_scale: 1000.0
  visibility_threshold: 0.05
  cut_boundary: 10
  n_split_points: 999999999
  num_rand_file_per_scene: 1
  out_dir: output_fusion
caption_head:
  NAME: CaptionHead
  POOLING_TYPE: avg
  FEAT_NORM: true
  LOGIT_SCALE:
    value: 100.0
    learnable: true
  CUDA_ENABLED: true
  POOL_OBJ: score
  LOSS_FUNC: NLL_NoReduce
  LOSS_WEIGHT:
    SCENE: 0.1
    VIEW: 0.5
    ENTITY: 0.1
  DIV_N_CAP: false
  DIV_MODE: none
  NOVEL_GRAD_ONLY: true
CAPTION_INFO:
  KEY:
  - SCENE
  - VIEW
  - ENTITY
  SCENE:
    ENABLED: false
    GATHER_CAPTION: true
  VIEW:
    ENABLED: true
    IMAGE_CORR_PATH: data/caption/small/scannet_view_matching_idx.pkl
    SELECT: ratio
    NUM: 1
    RATIO: 0.5
    GATHER_CAPTION: true
  ENTITY:
    ENABLED: true
    IMAGE_CORR_PATH: data/caption/small/caption_idx_small.pickle
    SELECT: ratio
    NUM: 1
    RATIO: 1.0
    GATHER_CAPTION: true
  CAPTION_CORR_PATH_IN_ONE_FILE: true
--config: config/scannet/xmask3d_scannet_B10N9.yaml
save_path: null
xdecoder_test/out/orihybgeo: null
resume: null
xdecoder_test/out/orihybgeo/model/affinity_predictor_epoch_34:
  pth: null

Loading teacher models...
/root/code/XMask3D/third_party/X-Decoder/xdecoder/modeling/BaseModel.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(load_dir, map_location=self.opt['device'])
Use prompt engineering: a XX in a scene
Final labelset: ['a wall in a scene', 'a floor in a scene', 'a cabinet in a scene', 'a bed in a scene', 'a chair in a scene', 'a sofa in a scene', 'a table in a scene', 'a door in a scene', 'a window in a scene', 'a bookshelf in a scene', 'a picture in a scene', 'a counter in a scene', 'a desk in a scene', 'a curtain in a scene', 'a refrigerator in a scene', 'a shower curtain in a scene', 'a toilet in a scene', 'a sink in a scene', 'a bathtub in a scene', 'background']
X-Decoder teacher loaded and frozen.
Loading checkpoint from HuggingFace: sonata ...
Model params: 108.46M
Sonata teacher loaded and frozen.
AffinityPredictor student created.
[2025-09-21 20:03:52,217 validation.py line 169] all_label: ['wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'bookshelf', 'picture', 'counter', 'desk', 'curtain', 'refrigerator', 'shower curtain', 'toilet', 'sink', 'bathtub']
arch_3d: MinkUNet34C
arch_binary_head: MinkUNet18A
aug: False
base_ratio: 0.65
batch_size: 4
batch_size_val: 1
binary_2d_thresh: 0.5
cam:
  alignment_dim: 512
  enable: True
  kl_temperature: 1.2
  loss_weight: 1.5
caption_contra: True
caption_contra_2d_pre: True
caption_contra_3d: True
caption_path: data/caption/caption_view_scannet_vit-gpt2-image-captioning_.json
category_split:
  all_category: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]
  base_category: [0, 1, 2, 3, 4, 5, 6, 7, 8, 13]
  ignore_category: [19, 20]
  novel_category: [9, 10, 11, 12, 14, 15, 16, 17, 18]
classes: 10
clip_name: ViT-L-14
data_ratio: 0.5
data_root: data/scannet_3d
data_root_2d: data/scannet_2d
dist_backend: nccl
dist_url: tcp://127.0.0.1:6745
distributed: False
entity_gt:
  contrastive_temp: 0.07
  enable: True
entity_path: data/caption/small/caption_entity_scannet_vit-gpt2-image-captioning_small.json
epochs: 100
eval_freq: 2
evaluate: True
ignore_label: 10
infer_batch_size_val: 1
infer_gpu: [0]
infer_workers: 1
input_color: True
label: ['wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa', 'table', 'door', 'window', 'curtain']
label_2d: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39]
learning_rate_type: cosine
loop: 16
loss_weight:
  entity_gt_loss: 1.5
  loss_3d: 4
  loss_3d_contra: 1
  loss_3d_pure: 4
  loss_binary: 10
  loss_explicit_contra: 1.5
  loss_explicit_contra_2d_pre: 4
  loss_explicit_contra_3d: 1.5
  pseudo_label: 1
lr_3d: 0.0001
lr_others: 0.0001
lseg_model_path: pretrained/weights/lseg/demo_e200.ckpt
manual_seed: 5557
mask_contra_3d: True
mask_shape: [484, 648]
momentum: 0.9
multiprocessing_distributed: False
ngpus_per_node: 1
novel_ratio: 0.2
num_queries: 200
pixel_mean: [0.0, 0.0, 0.0]
pixel_std: [255.0, 255.0, 255.0]
power: 0.9
print_freq: 10
prompt_eng: True
pseudo_label:
  enable: True
  infer_boost_only_novel_pred: False
  infer_caption_boost_factor: 0.3
  infer_use_caption_boost: True
  scores_keep_thresh: 0.05
  temperature: 0.07
  use_view_entities: True
rank: 0
resume: xdecoder_test/out/orihybgeo/model/affinity_predictor_epoch_34.pth
save_freq: 1
save_path: xdecoder_test/out/orihybgeo
scannet200: False
scores_keep_thresh: 0
scores_threshold: 0.0
start_contra: 0
start_epoch: 0
test_classes: 19
test_ignore_label: [19, 20]
train_gpu: [0]
train_s: True
use_ape: False
use_shm: False
val_keep: 10000000
voxel_size: 0.02
warmup_epochs: 2
weight_decay: 1e-05
workers: 2
world_size: 1
[2025-09-21 20:03:52,218 validation.py line 170] => creating model ...
[2025-09-21 20:03:52,218 validation.py line 174] => setting up optimizer with differential learning rates...
[2025-09-21 20:03:52,238 validation.py line 212] => loading checkpoint 'xdecoder_test/out/orihybgeo/model/affinity_predictor_epoch_34.pth'
/root/code/XMask3D/xdecoder_test/validation.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.resume, map_location=device)
[2025-09-21 20:03:52,666 validation.py line 256] => loaded checkpoint 'xdecoder_test/out/orihybgeo/model/affinity_predictor_epoch_34.pth' (will start from epoch 35)
Loading files based on specific_ids: ['scene0696_02', 'scene0203_02', 'scene0550_00', 'scene0474_04', 'scene0307_00', 'scene0329_02', 'scene0030_00scene0169_00', 'scene0616_00', 'scene0653_01']
Loaded 8 files based on specific_ids
Preprocessing dataset to create (scene, view) samples...
Loading scene configs:   0%|          | 0/8 [00:00<?, ?it/s]Found pose directory, assuming ScanNet data set!
Loading Training Cameras...
Loading Test Cameras...
Loading scene configs:  12%|█▎        | 1/8 [00:17<02:02, 17.56s/it]Found pose directory, assuming ScanNet data set!
Loading Training Cameras...
Loading Test Cameras...
